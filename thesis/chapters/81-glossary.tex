\chapter{Glossary}
\label{chapter:glossary}

{%
    \noindent
    \renewcommand{\arraystretch}{1.5}
    \begin{longtable}{>{\bfseries}l l p{0.75\textwidth}}
        ABOF
        &–&
        \textbf{A}ngle-\textbf{B}ased \textbf{O}utlier \textbf{F}actor
        \par
        \small
        A measure to quantity the similarity of the data.
        \newline
        See: section \ref{section:ABOF}
        \\

        BERT
        &–&
        \textbf{B}idirectional \textbf{E}ncoder \textbf{R}epresentations from \textbf{T}ransformers
        \par
        \small
        A transformer model designed for NLP tasks.
        \newline
        See: section \ref{section:BERT}
        \\

        BoW
        &–&
        \textbf{B}ag \textbf{o}f \textbf{W}ords
        \par
        \small
        A way to represent text documents as feature vectors.
        \\

        CLIP
        &–&
        \textbf{C}ontrastive \textbf{L}anguage-\textbf{I}mage \textbf{P}re-training
        \par
        \small
        A method for image classification with transformer-based architecture.
        \newline
        See: section \ref{section:CLIP}
        \\

        CoCa
        &–&
        \textbf{Co}ntrastive \textbf{Ca}ptioners
        \par
        \small
        A method for image classification with transformer-based architecture.
        \newline
        See: section \ref{section:CoCa}
        \\

        CNN
        &–&
        \textbf{C}onvolutional \textbf{N}eural \textbf{N}etwork
        \par
        \small
        An architecture of machine learning models that, utilizing principles of linear algebra,
        are capable of extracting features and identify patterns from data without any prior knowledge.
        \\

        DL
        &–&
        \textbf{D}eep \textbf{L}earning
        \par
        \small
        A subset of ML that utilizes the complex multilayered neural networks.
        \\

        Doc2Vec
        &–&
        \textbf{Doc}ument \textbf{to} \textbf{Vec}tor
        \par
        \small
        An algorithm to generate feature vectors from text documents.
        \newline
        See: section \ref{section:Doc2Vec}
        \\

        ED
        &–&
        \textbf{E}uclidean \textbf{D}istance
        \par
        \small
        A measure to quantity the similarity of the data.
        \newline
        See: section \ref{section:Euclidean}
        \\

        FN
        &–&
        \textbf{F}alse \textbf{N}egative
        \par
        \small
        A number of known data incorrectly recognized as an outlier,
        \newline
        See: section \ref{section:verification}
        \\

        FP
        &–&
        \textbf{F}alse \textbf{P}ositive
        \par
        \small
        A number of unknown data incorrectly recognized as an inlier.
        \newline
        See: section \ref{section:verification}
        \\

        IAOF
        &–&
        \textbf{I}nterquartile \textbf{A}ngle-based \textbf{O}utlier \textbf{F}actor
        \par
        \small
        A measure to quantity the similarity of the data.
        \\

        ID
        &–&
        \textbf{I}n-\textbf{D}istribution
        \par
        \small
        The typical data that are not likely to be outliers.
        \\

        IRWD
        &–&
        \textbf{I}ntegrated \textbf{R}ank \textbf{W}eighted \textbf{D}epth
        \par
        \small
        A measure to quantity the similarity of the data.
        \newline
        See: section \ref{section:IRWD}
        \\

        kNN
        &–&
        \textbf{k}-\textbf{N}earest \textbf{N}eighbors
        \par
        \small
        An algorithm for identifying closest neighbor points located in space.
        \newline
        See: section \ref{section:kNN}
        \\

        LOF
        &–&
        \textbf{L}ocal \textbf{O}utlier \textbf{F}actor
        \par
        \small
        A measure to quantity the similarity of the data.
        \newline
        See: section \ref{section:LOF}
        \\

        MD
        &–&
        \textbf{M}ahalanobis \textbf{D}istance
        \par
        \small
        A measure to quantity the similarity of the data.
        \newline
        See: section \ref{section:Mahalanobis}
        \\

        MDP
        &–&
        \textbf{M}ahalanobis \textbf{D}istance with \textbf{P}ooled covariance matrix
        \par
        \small
        A measure to quantity the similarity of the data.
        \newline
        See: section \ref{section:Mahalanobis}
        \\

        ML
        &–&
        \textbf{M}achine \textbf{L}earning
        \par
        \small
        A branch of Computer Science focused on imitating the way that humans learn, to produce tools to recognize and classify the data.
        \\

        MVN
        &–&
        \textbf{M}ulti\textbf{v}ariate \textbf{N}ormal distribution
        \par
        \small
        A generalized normal/Gaussian distribution for multiple dimensions.
        \\

        NLP
        &–&
        \textbf{N}atural \textbf{L}anguage \textbf{P}rocessing
        \par
        \small
        A branch of Machine Learning focused on analyzing text data.
        \\

        NN
        &–&
        \textbf{N}eural \textbf{N}etwork
        \par
        \small
        A ML model that simulates the operation of biological neurons.
        \\

        OOD
        &–&
        \textbf{O}ut-\textbf{o}f-\textbf{D}istribution
        \par
        \small
        The abnormal data that are likely outliers for a given distribution.
        \\

        OF
        &–&
        \textbf{O}utlier \textbf{F}actor
        \par
        \small
        A measure of similarity used by OOD detector (general term).
        \newline
        See: section \ref{section:measures}
        \\

        PCA
        &–&
        \textbf{P}rincipal \textbf{C}omponent \textbf{A}nalysis
        \par
        \small
        A method to reduce the dimensionality of feature vectors.
        \\

        ResNet
        &–&
        \textbf{Res}idual \textbf{Net}works
        \par
        \small
        A method for image classification that utilizes CNN architecture.
        \newline
        See: section \ref{section:ResNet}
        \\

        RP
        &–&
        \textbf{R}andom \textbf{P}rojection
        \par
        \small
        A method to reduce the dimensionality of feature vectors.
        \\

        SED
        &–&
        \textbf{S}tandardized \textbf{E}uclidean \textbf{D}istance
        \par
        \small
        A measure to quantity the similarity of the data.
        \newline
        See: section \ref{section:SEuclidean}
        \\

        TF-IDF
        &–&
        \textbf{T}erm \textbf{F}requency – \textbf{I}nverse \textbf{D}ocument \textbf{F}requency
        \par
        \small
        A way to represent text documents as feature vectors.
        \\

        TN
        &–&
        \textbf{T}rue \textbf{N}egative
        \par
        \small
        A number of unknown data correctly recognized as an outlier,
        \newline
        See: section \ref{section:verification}
        \\

        TP
        &–&
        \textbf{T}rue \textbf{P}ositive
        \par
        \small
        A number of known data correctly recognized as an inlier.
        \newline
        See: section \ref{section:verification}
        \\

        ViT
        &–&
        \textbf{Vi}sion \textbf{T}ransformer
        \par
        \small
        A method for image classification with transformer-based architecture.
        \newline
        See: section \ref{section:ViT}
        \\
    \end{longtable}
}
