\chapter{Summary}
\label{chapter:summary}

In this work the problem of open-set classification in high-dimensional feature spaces was explored. It is a~key task to be solved to ensure the security of implementations and the reliability of machine learning models – in particular: deep learning models for image and text recognition; allowing the systems that utilize such models to react predictably to new data and unexpected situations. Although the~problem remains open, the conducted research contributes to the field, introducing new insights of the selected \textit{post-hoc} methods behaviors and properties, as well as providing recommendations of outlierness measures and high-dimensional representation techniques for applications involving image and text data.

A comprehensive study on the performance of selected \textit{post-hoc} methods for outliers detection was conducted. Primarily, it was shown that the performance of OOD detectors is dependent on the properties of the representation – i.e., of the feature space in which the recognition of outliers is performed. This problem is not sufficiently noticed in the existing literature – the rankings of methods in benchmarks are presented, comparing results for various representations or showing results for a~fixed selected representation (usually ResNet) without emphasizing it, making the formulated general conclusions turning out to be not useful when new representations or out-of-distribution detection methods are analyzed.

One of the most interesting observation is related to the phenomenon that the measures can consider training and testing data coming from the same distribution (ID) as distant from each other, i.e., testing data may be considered outliers with respect to the available training samples. For ED, SED and IRWD measures it is only observed for highly under-represented training cluster for a~given dimension, i.e., $n \ll d$, and quickly vanishes as number of training samples grows. For MD measure this phenomenon is observed unless a~significantly great number of training samples is provided, $n \gg d$, which in high-dimensional feature spaces becomes troublesome. In case of kNN, the phenomenon is also observed and it is related to the selected value of $k$ – for low value $k$ the train-test distance is greater than for higher values of $k$. Detailed research of this effect for kNN shall be conducted in the future. For ABOF and LOF measures this phenomenon was not observed even under extreme conditions.

Despite the observed train-test data distancing, all analyzed outlierness measures can still reliably distinct the in-distribution (ID) data from sufficiently distant out-of-distribution (OOD, outliers), which is proven by the calculated AUROC scores. However, this means that in some cases, notably for MD and kNN, the threshold calibration for the open-set classification task requires involvement of the additional validation in-distribution data to achieve correct results, although reliability of such approach may be questionable.

For all analyzed measures, the more distant the outliers were from the in-distribution samples, the higher AUROC scores were observed. Contrary, higher dimension $d$ of feature vectors made the separability between in-distribution and out-of-distributon data more challenging. The number of training samples $n$ did not affect much the methods performance for a~given fixed $d$ and~$h$, except for the extreme conditions (e.g.~$n < 10^2$ for $d = 750$) or MD measure, where there is a~computational requirement $n \geq d$ (condition for inverting the covariance matrix used in distance formula).

The results of numerical study were compared with the open-set classification task conduced on the real-world data, utilizing feature vectors produced by multiple representation algorithms – CLIP, CoCa, ConvNeXT, EfficientNet, ResNet and Vit for image data; BERT, Doc2Vec, fastText and TF-IDF for text documents. Future work in this field shall conduct more comprehensive study, involving the research focused on other domains than image and text recognition – for example AI in medicine, such as the bacteria identification based on genomic sequences \cite{Ren-2019}\cite{Fort-2021}, where the OOD detection is the essential element in real-world applications.

It was shown that for all analyzed cases there exist a~notable number of classes that contain samples much more difficult to distinguish from outliers. Such classes pose an~important security gap in the deployed machine learning system. Hence, the per-class analysis of~ID-OOD separability is proposed as a~recommended approach any safety-critical applications.
Further work in this topic should involve a~detailed focus on those classes – the curious question remains if those are the same classes for all outlierness measures and representation algorithms, and notably why such classes are characterized by poor performance in the outliers detection task.


\section{Recommendations for OOD detection with Deep Learning models}
\label{section:real-recommendations}

Based on the conducted study, the following recommendations regarding the usage of OOD detection methods can be formulated, assuming the task in image and text recognition domain using Deep Learning representation methods.
\vspace{-0.5\baselineskip}
\begin{enumerate}
    \item The OOD detector based on the Mahalanobis distance with a single, common covariance matrix for all classes of the known ID set (i.e., pooled variant, MDP) should be avoided and not used – it is always less effective in outlier detection task than the original variant (MD), which involves a separate covariance matrix calculated for each ID class, or the variant with diagonal covariance matrix (SED), which assumes no correlations between features. The selection between MD and SED can be made by analysis of the representation characteristics – for model with no or low correlations of features, such as ResNet, the SED is preferred.
    \item The operating point, i.e., OOD detection threshold (formula \ref{eq:open-set-classification}), of detectors based on popular kNN and MD measures, cannot be calibrated on the condition that a~given fraction of training data (e.g., $95\%$) will be correctly recognized. For~such measures, the procedure results in a~low sensitivity of ID recognition by the detector. An additional, independent set of validation data must be used to calibrate detectors based on such measures. However, other OOD detectors, e.g., utilizing LOF and SED, can be successfully calibrated on just the training in-distribution (ID) data.
    \item The selection of OOD detector in real-world implementations of the Machine Learning systems should be made based on the analysis of the representations characteristics generated by the Deep Learning models. For example, for the ResNet model the preferred OOD detector involves SED measure, while for the ViT model both LOF and MD performs best. The OOD detector rankings and recommendations made for a fixed representation (Deep Learning model) do not transfer to other models.
    \item The data representation models generated by various Deep Learning techniques (e.g., CNN, ViT, CLIP) differ significantly in therms of OOD-generalization, i.e., the~susceptibility to errors of incorrect identifications of OOD observations. Hence, in any safety-critical task, it is recommended to utilize either CLIP, CoCa or ConvNeXT models, as offering the best results in general. Models such as ResNet, EfficientNet and ViT bear a~greater risk of OOD data incorrect recognition.
    \item The implementation of the AI system in the real-world tasks, especially for safety-critical ones, should be preceded with an analysis of OOD-generalization per every known class. This will allow to identify the security gaps in the system by capturing the classes with low OOD-generalization, i.e., classes that are easier to confuse with out-of-distribution data, i.e., are more prone to incorrect recognition.
\end{enumerate}

Relying on these above recommendations will improve the quality of OOD observations recognition, therefore resulting in improved trustworthiness of Machine Learning systems in real-world and safety-critical applications.

\cleardoublepage{}
