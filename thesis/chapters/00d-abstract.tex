\phantomsection  % so hyperref links will lead to the correct place in document
\addcontentsline{toc}{chapter}{Abstract}

\chapter*{Abstract}
\label{chapter:abstract}

This work explores the topic of open-set classification problem in high-dimensional data. It is a task of identifying new data – outliers or out-of-distribution examples (OOD), that significantly differ from any previously available/known samples, i.e., training data used to build the closed-set classifier. While this task is strongly grounded and described with a solid statistical background in general, it turns out to~be challenging and still not resolved for high-dimensional feature spaces, where all the~current approaches and measures are proving to be insufficient. Furthermore, although many OOD detection methods for this task were proposed recently, the vast literature provides contradicting recommendations on solutions.

The motivation for undertaking this research problem lies in the rapid progress and astonishing performance of deep learning models (CNNs or ViTs) for images classification reported in benchmarks. These models involve high-dimensional feature representations ($d \sim 10^3$), however they are still based on closed-set recognition. Recent advancements in the machine learning domain and popularization of the artificial intelligence tools, such as the emergence of the complex deep learning techniques and the growing interest in self-driving cars, as well as other autonomous vehicles – all this makes the issues of reliability and safety extremely important topics nowadays. The problem of outliers detection fits into this theme, as one of the crucial aspects related to the machine learning models robustness is the models ability to adapt to the new data and situations. In any real-world and safety-critical implementation of machine learning-based systems, the reliable OOD-detection is a fundamental requirement to ensure safety in cases missed or not considered during the model training. Yet, as pointed out by leading scientists in the field, such aspects remain under-explored in literature so far.

This dissertation consists of three major parts. In first sections, the necessary background of outlier detection techniques is covered, focusing on distinguishing main approaches already proposed in literature. A detailed description of selected \textit{post-hoc} methods is provided, as well as the required formalization and notation of the open-set classification task. The main research interest is concentrated on methods that are implemented to work in the feature spaces because of their universality – the possibility to apply them for any existing, pre-trained model.

Then, the biggest chapter describes the results of a~conducted numerical study on the~simulated data distributions. The performance of selected \textit{post-hoc} methods for outliers detection is analyzed, considering such factors as dimensions of feature vectors, numbers of training samples and distance to outliers – to examine how well various methods can distinguish both training and testing samples from the~outliers. Additionally, the effects of correlations presence in the data on the methods performances are analyzed, as well as the behaviors of the methods when the features are characterized by non-uniform variances, i.e., data are unstandardized. The conducted research shows non-obvious behaviors of some of the examined methods, which is especially visible in~higher dimensions of feature vectors. The work presents that the methods possess significantly different potentials for distinguishing between the known data (in-distribution, ID) and the unknown data (out-of-distribution, OOD). Moreover, the research identified the required conditions for methods to maintain accurate representations of~data.

Finally, an evaluation involving the real-world data is performed. A~wide range of pre-trained representation algorithms is used to obtain the feature vectors representations of~text documents and image data, that are then examined for their potential in the~open-set classification task with respect to the training data. A~number of~significant differences between the representations are observed and discussed. It turns out that the properties of representations greatly impact the performance of OOD detectors in the task. Hence, guidelines for selection of methods suitable for a particular representation can be formulated. It is shown that for all analyzed cases there exist a~notable number of classes that contain samples much more difficult to distinguish from outliers, hence the per-class analysis of~ID-OOD separability is proposed for the safety-critical applications. Such evaluation allows to identify security gaps and risks related to classes with poor OOD-generalization, that may require more in-depth analysis.

The conducted research contributes to the field by providing a novel insight of the selected \textit{post-hoc} methods behaviors and properties in the high-dimensional feature spaces. The recommendations for the selection, usage and calibration of OOD methods for particular data representations in the outliers detection task are provided, involving applications on image and text data.


\section*{Keywords}
\label{section:keywords}

\begin{itemize}
    \item[–] Open-Set Classification.
    \item[–] Out-of-Distribution Detection.
    \item[–] Measures of Outlierness.
    \item[–] High-Dimensional Feature Vectors.
    \item[–] Data Representation Techniques.
\end{itemize}
